{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import re\n",
        "\n",
        "# Necessary resources download\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = \"\"\" \"\"\"\n",
        "\n",
        "# Stop words and punctuations removal, special characters and extra spaces removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words]\n",
        "clean_text = re.sub('\\W+', ' ', text)\n",
        "clean_text = re.sub('\\s+', ' ', clean_text)\n",
        "\n",
        "# Text conversion into a list of sentences and sentence scores calculation\n",
        "sentences = sent_tokenize(clean_text)\n",
        "sentence_scores = {sentence: sum(word in words for word in word_tokenize(sentence.lower()))/len(sentences) for sentence in sentences}\n",
        "\n",
        "# Dynamic summary generation\n",
        "summary_sentences = []\n",
        "sorted_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
        "while sorted_sentences and len(' '.join(summary_sentences)) < 500:\n",
        "    sentence = sorted_sentences.pop(0)\n",
        "    if len(' '.join(summary_sentences + [sentence])) <= 800:\n",
        "        summary_sentences.append(sentence)\n",
        "\n",
        "summary = ' '.join(summary_sentences) if summary_sentences else '요약할 수 있는 문장이 없습니다.'\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Summary:\", summary)\n",
        "print(\"Length of Original Text:\", len(text))\n",
        "print(\"Length of Summary:\", len(summary))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFbqta-Kto8o",
        "outputId": "e4b791a8-f007-4c53-84e3-0fe826cb159e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: 캐글 강화학습 코스 프로젝트 제안서\n",
            "AI융합학부 20211371 윤선미\n",
            "1.\t기획 사유\n",
            "캐글 강화학습 코스(Intro to Game AI and Reinforcement Learning)를 프로젝트로 진행하게 된 이유는 강화학습을 사용한 게임을 진행하면서 강화학습의 기본 개념과 용어를 소개하며, SARSA, Q-Learning, Policy Gradient 등의 강화학습 알고리즘등을 구현하는 방법을 쉽게 접할 수 있기 때문입니다, 또한, 이 코스를 강화학습으로 진행하는 이유는 강화학습 에이전트는 경험을 쌓는 과정을 통해 실수를 배우기 때문에 불리한 상황에서도 학습을 통해 최선의 결정을 내리는 방법을 계속해서 발견하여 더 나은 성능을 발휘할 수 있으며, 강화학습 에이전트가 경험을 통해 스스로 학습하는 점이 고정된 전략보다는 유연하게 해결할 수 있을 것이라고 생각했기 때문입니다.\n",
            "2.\t기본 정보 및 해결 방안 계획\n",
            "이 코스는 Connect Four 게임을 강화학습으로 해결합니다. 먼저, Connect Four 게임은, 두 명의 플레이어가 번갈아 가며 컬러 디스크를 7X6 수직 그리드에 떨어뜨리는 게임입니다. 각 플레이어는 색이 다른 디스크를 사용하여 연속해서 디스크 4개를 먼저 얻는 플레이어가 승리하는 방식입니다.  \n",
            "첫 번째 코스에서는 Connect Four 게임을 플레이하는 첫 번째 에이전트를 만드는 방법에 대해 배웁니다. 에이전트를 만드는 방법은 게임 환경을 설정한 후에 게임을 어떻게 플레이 할 지에 대한 방법을 정하는 에이전트를 정의하고 에이전트의 성능을 평가합니다\n",
            "두 번째 코스는 One-Step Lookahead입니다. 여기서는 휴리스틱을 이용하여 게임 에이전트에 지식을 전달하는 방법을 배우고, 게임 트리를 사용하여 모든 게임결과를 예측하고 휴리스틱을 통해 최상의 움직임을 만드는 방법에 대해 개발합니다. \n",
            "세 번째 코스는 N-Step Lookahead입니다 여기에서는 미니맥스 알고리즘을 사용하여 게임의 여러 단계를 예측하고 최선의 움직임을 선택하는 방법을 배웁니다. 최선의 움직임을 선택하고 상대방은 최악의 경우를 가정하여 게임 전략을 계획하는 방법을 배웁니다. \n",
            "마지막 네 번째 코스는 Deep Reinforcement Learning입니다 여기에선, 강화학습을 사용하여 플레이하는 인공 에이전트를 훈련시키는 방법을 설명하고 있으며, 강화학습 알고리즘을 이용해 특히 휴리스틱을 사용하지 않고 대신 에이전트가 게임을 플레이하며 승률을 최대화하기 위한 전략을 점진적으로 개선하는 방법에 대해서 배웁니다 \n",
            "저는 이 네 개의 코스를 10주차 전까지 진행해보고, 10주차부터 12주차까지 혼자만의 최상의 에이전트를 직접 만들기 위해 휴리스틱 함수를 더 개선하여 더 정교한 점수를 할당할 수 있도록 하거나, 더 깊은 게임 트리를 탐색할 수 있는 방법에 대해 공부하고 코스에서 배운 다양한 알고리즘을 더 많이 공부하여 비교한 후 최상의 에이전트 정책을 만들 수 있도록 할 것입니다. 만약, 필요한 경우 에이전트의 성능을 평가한 후 하이퍼파라미터를 조정해보려고 합니다.\n",
            "3.\t기대효과 \n",
            "이 프로젝트를 통해 강화학습에 대한 전반적인 지식을 습득하고, 게임이라는 친숙하고 재밌는 방법으로 강화학습에 더 많은 흥미를 가지게 되는 계기가 되기를 바랍니다. \n",
            "\n",
            "Summary: 요약할 수 있는 문장이 없습니다.\n",
            "Length of Original Text: 1607\n",
            "Length of Summary: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}